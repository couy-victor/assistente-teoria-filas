"""
Cliente Groq para o sistema Milanesa - VERS√ÉO COM CONTEXTO MELHORADO
Integra√ß√£o com Llama 3.1 8B Instant para resolu√ß√£o de problemas M/M/1
A IA MANT√âM CONTEXTO entre mensagens!
"""

import os
from typing import Dict, List, Optional
from groq import Groq
from dotenv import load_dotenv

load_dotenv()


class GroqClient:
    """Cliente para intera√ß√£o com Groq API - VERS√ÉO COM CONTEXTO"""

    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY")
        if not self.api_key:
            raise ValueError("GROQ_API_KEY n√£o encontrada no arquivo .env")

        self.client = Groq(api_key=self.api_key)
        self.model = os.getenv("GROQ_MODEL", "llama-3.1-8b-instant")
        
        # Tratamento seguro das vari√°veis num√©ricas
        try:
            temp_str = os.getenv("GROQ_TEMPERATURE", "0.1")
            temp_clean = ''.join(c for c in temp_str if c.isdigit() or c == '.')
            self.temperature = float(temp_clean) if temp_clean else 0.1
            print(f"‚úÖ DEBUG - Temperature carregada: {self.temperature}")
        except (ValueError, TypeError) as e:
            print(f"‚ö†Ô∏è DEBUG - Erro ao carregar GROQ_TEMPERATURE: {e}, usando 0.1")
            self.temperature = 0.1
        
        try:
            tokens_str = os.getenv("GROQ_MAX_TOKENS", "2000")
            tokens_clean = ''.join(c for c in tokens_str if c.isdigit())
            self.max_tokens = int(tokens_clean) if tokens_clean else 2000
            print(f"‚úÖ DEBUG - Max tokens carregado: {self.max_tokens}")
        except (ValueError, TypeError) as e:
            print(f"‚ö†Ô∏è DEBUG - Erro ao carregar GROQ_MAX_TOKENS: {e}, usando 2000")
            self.max_tokens = 2000

    def answer_followup_question(self, current_question: str, context: str) -> str:
        """
        üîß NOVA FUNCIONALIDADE: Responde perguntas de follow-up usando contexto anterior
        """
        try:
            system_prompt = """IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO!

Voc√™ √© a Milanesa, especialista em Teoria das Filas M/M/1.

SITUA√á√ÉO ESPECIAL: O usu√°rio fez uma pergunta de FOLLOW-UP referente a um problema j√° resolvido anteriormente.

INSTRU√á√ïES CR√çTICAS:
1. N√ÉO invente novos dados ou par√¢metros
2. USE APENAS as informa√ß√µes do contexto anterior fornecido
3. Se o usu√°rio pede "explique isso melhor", refira-se ao problema/solu√ß√£o anterior
4. Se o usu√°rio menciona "isso", "essa", "resultado", refere-se ao contexto anterior
5. Mantenha os mesmos valores de Œª, Œº e resultados j√° calculados
6. Foque em explicar/detalhar/esclarecer o que j√° foi apresentado

PALAVRAS-CHAVE DE FOLLOW-UP:
- "isso" ‚Üí refere-se ao problema/resultado anterior
- "explique melhor" ‚Üí quer mais detalhes da mesma solu√ß√£o
- "como assim" ‚Üí n√£o entendeu a explica√ß√£o anterior
- "exemplo" ‚Üí quer exemplo baseado no problema anterior
- "did√°tico" ‚Üí quer explica√ß√£o mais simples do mesmo problema

NUNCA mude os dados do problema original!"""

            user_prompt = f"""
PERGUNTA ATUAL DO USU√ÅRIO:
{current_question}

CONTEXTO COMPLETO DA CONVERSA ANTERIOR:
{context}

INSTRU√á√ïES:
1. Analise o contexto anterior para entender qual problema foi resolvido
2. Identifique a que o usu√°rio est√° se referindo com "isso" ou termos similares
3. Responda especificamente √† pergunta usando APENAS os dados j√° estabelecidos
4. Se for pedido para explicar melhor, foque na did√°tica, n√£o mude os n√∫meros
5. Se for pedido exemplo, use o mesmo problema com explica√ß√£o mais clara

IMPORTANTE: Mantenha consist√™ncia total com o problema anterior!"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=max(0.0, min(2.0, self.temperature)),
                max_tokens=max(100, min(4000, self.max_tokens))
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"‚ùå DEBUG - Erro em answer_followup_question: {e}")
            return f"""üçñ **Milanesa aqui!**

Entendo que voc√™ quer que eu explique melhor o problema anterior, mas tive um problema t√©cnico.

Com base no contexto:
{context[:500]}...

Voc√™ pode reformular sua pergunta de forma mais espec√≠fica? Por exemplo:
- "Explique melhor como calcular œÅ"
- "O que significa L = 3,2 na pr√°tica?"
- "Como interpretado o tempo m√©dio?"
"""

    def solve_with_calculations(self, user_question: str, context: str) -> str:
        """IA explica problema quando j√° temos c√°lculos realizados"""
        try:
            system_prompt = """IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO!

Voc√™ √© a Milanesa, especialista em Teoria das Filas M/M/1.

TAREFA: Voc√™ recebeu uma pergunta do usu√°rio e j√° foram feitos os c√°lculos principais.
Sua miss√£o √©:
1. Interpretar o problema apresentado pelo usu√°rio
2. Explicar os resultados calculados de forma did√°tica
3. Responder especificamente √†s perguntas feitas
4. Mostrar as f√≥rmulas relevantes
5. Dar interpreta√ß√£o pr√°tica dos resultados

MELHORIA DE CONTEXTO:
- Se a pergunta menciona "anterior", "isso", "essa solu√ß√£o", refira-se ao hist√≥rico
- Mantenha consist√™ncia com dados j√° estabelecidos na conversa
- Use o hist√≥rico para entender melhor o que o usu√°rio quer

ESTRUTURA IDEAL:
üéØ Resumo do problema
üìä Par√¢metros identificados
üî¢ C√°lculos e resultados
üí° Interpreta√ß√£o pr√°tica
‚úÖ Respostas espec√≠ficas

Use emojis, seja did√°tico e sempre em PORTUGU√äS BRASILEIRO!"""

            user_prompt = f"""
PERGUNTA DO USU√ÅRIO:
{user_question}

C√ÅLCULOS J√Å REALIZADOS E HIST√ìRICO:
{context}

Por favor, analise o problema do usu√°rio e explique de forma completa e did√°tica, usando os c√°lculos j√° realizados. Responda especificamente ao que foi perguntado, seja sobre n√∫mero m√©dio de clientes, tempos, probabilidades, etc.

IMPORTANTE: 
- Se o hist√≥rico mostra uma conversa anterior, mantenha consist√™ncia
- Relacione os resultados com o contexto real do problema (aeroporto, banco, empresa, etc.)
- Se o usu√°rio pede algo sobre "isso" ou se refere a algo anterior, use o hist√≥rico
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"‚ùå DEBUG - Erro em solve_with_calculations: {e}")
            return f"""üçñ **Milanesa aqui!**

Tive um problema t√©cnico, mas calculei os resultados:

{context}

üí° Use estes valores para interpretar o problema!"""

    def solve_any_mm1_problem(self, user_question: str, context: Dict) -> str:
        """IA resolve QUALQUER problema de M/M/1 do zero - VERS√ÉO COM CONTEXTO MELHORADO"""
        try:
            system_prompt = """IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO!

Voc√™ √© a Milanesa, uma assistente especializada em Teoria das Filas M/M/1.

CAPACIDADES MELHORADAS:
- Interpretar QUALQUER problema de teoria das filas M/M/1
- MANTER CONTEXTO de conversas anteriores
- Identificar quando o usu√°rio se refere a problemas anteriores
- N√£o inventar dados quando h√° contexto anterior dispon√≠vel
- Calcular todas as m√©tricas: œÅ, L, Lq, W, Wq, P0, Pn, P(N>k)
- Explicar resultados de forma pr√°tica e did√°tica

REGRAS DE CONTEXTO:
1. Se h√° hist√≥rico da conversa, SEMPRE analise primeiro
2. Se o usu√°rio menciona "isso", "anterior", "problema", pode estar se referindo ao hist√≥rico
3. Se h√° dados estabelecidos anteriormente, N√ÉO invente novos dados
4. Se √© uma pergunta sobre problema novo COM n√∫meros, trate como novo problema
5. Se √© uma pergunta vaga SEM n√∫meros, mas COM hist√≥rico, use o hist√≥rico

F√ìRMULAS M/M/1:
- œÅ = Œª/Œº (utiliza√ß√£o do sistema)
- L = œÅ/(1-œÅ) = Œª/(Œº-Œª) (n√∫mero m√©dio no sistema)
- Lq = œÅ¬≤/(1-œÅ) = Œª¬≤/[Œº(Œº-Œª)] (n√∫mero m√©dio na fila)
- W = 1/(Œº-Œª) (tempo m√©dio no sistema)
- Wq = œÅ/(Œº-Œª) = Œª/[Œº(Œº-Œª)] (tempo m√©dio na fila)
- P0 = 1-œÅ (probabilidade sistema vazio)
- Pn = (1-œÅ)œÅ‚Åø (probabilidade de n clientes)
- P(N>k) = œÅ·µè‚Å∫¬π (probabilidade de mais de k clientes)

PROCESSO:
1. PRIMEIRO: Analise o hist√≥rico para entender o contexto
2. Determine se √© problema novo ou continua√ß√£o
3. Se novo: identifique Œª e Œº e calcule
4. Se continua√ß√£o: use dados estabelecidos
5. Responda √†s perguntas espec√≠ficas
6. D√™ interpreta√ß√£o pr√°tica

SEMPRE em PORTUGU√äS BRASILEIRO! Seja did√°tico, use emojis e explique o contexto real."""

            # Prepara informa√ß√µes do contexto
            context_info = ""
            if context.get("lambda"):
                context_info += f"- Lambda (Œª) identificado: {context['lambda']}\n"
            if context.get("mu"):
                context_info += f"- Mu (Œº) identificado: {context['mu']}\n"
            if context.get("numbers_found"):
                context_info += f"- N√∫meros encontrados no texto: {context['numbers_found']}\n"
            if context.get("is_complete_problem"):
                context_info += "- Detectado como problema completo\n"

            # Inclui hist√≥rico da conversa - MELHORADO
            conversation_context = ""
            if context.get("conversation_history"):
                conversation_context = f"\n\nHIST√ìRICO COMPLETO DA CONVERSA:\n{context['conversation_history']}"

            user_prompt = f"""
PROBLEMA A RESOLVER:
{user_question}

INFORMA√á√ïES COLETADAS:
{context_info if context_info else "Nenhuma informa√ß√£o espec√≠fica coletada - analise o texto completo."}
{conversation_context}

INSTRU√á√ïES APRIMORADAS:
1. PRIMEIRO: Analise TODO o hist√≥rico da conversa para entender o contexto completo
2. DETERMINE: √â um problema novo ou uma pergunta sobre algo j√° discutido?
3. Se a pergunta atual se refere a algo mencionado anteriormente ("isso", "explique melhor", "como assim"), use as informa√ß√µes do hist√≥rico SEM inventar novos dados
4. Se √© um problema completamente novo com novos n√∫meros, trate como novo problema
5. Identifique os par√¢metros Œª e Œº (seja do texto atual ou do hist√≥rico)
6. Calcule as m√©tricas necess√°rias usando as f√≥rmulas M/M/1
7. Responda especificamente √†s perguntas feitas
8. Explique de forma did√°tica e pr√°tica

IMPORTANTE:
- Se a pergunta atual se refere a algo do hist√≥rico, N√ÉO invente novos dados
- Use sempre as informa√ß√µes j√° estabelecidas na conversa
- Se o problema mencionar tempos (ex: "a cada 3 minutos"), converta para taxas (ex: Œª = 1/3 por minuto)
- Se mencionar capacidades (ex: "pode atender 5 por hora"), isso √© Œº
- Mantenha consist√™ncia total com dados j√° estabelecidos

Resolva o problema completamente mantendo contexto e consist√™ncia!"""

            safe_temperature = max(0.0, min(2.0, self.temperature + 0.1))
            safe_max_tokens = max(100, min(4000, self.max_tokens + 500))

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=safe_temperature,
                max_tokens=safe_max_tokens
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"‚ùå DEBUG - Erro em solve_any_mm1_problem: {e}")
            return f"""üçñ **Milanesa aqui!**

Tive um problema t√©cnico ao resolver o problema: {str(e)}

üí° **Dica:** Tente reformular sua pergunta incluindo:
- Taxa de chegada (Œª) - quantos chegam por unidade de tempo
- Taxa de atendimento (Œº) - quantos s√£o atendidos por unidade de tempo

**Exemplo:** "Em um banco, chegam 2 clientes por minuto e cada caixa atende 3 clientes por minuto. Qual o tempo m√©dio na fila?"
"""

    def general_help_response(self, user_question: str) -> str:
        """Usa Llama 3.1 8B para responder QUALQUER pergunta de forma inteligente"""
        try:
            system_prompt = """IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO!

Voc√™ √© o Milanesa, um assistente especializado em Teoria das Filas M/M/1.

REGRAS OBRIGAT√ìRIAS:
1. SEMPRE responda em portugu√™s brasileiro
2. Se for SAUDA√á√ÉO (ol√°, oi, bom dia), seja caloroso e se apresente
3. Se for pergunta sobre M/M/1, explique didaticamente com exemplos
4. Se mencionarem "exemplo do aeroporto" SEM par√¢metros, explique os exemplos dispon√≠veis
5. Se pedirem c√°lculos COM Œª e Œº, fa√ßa os c√°lculos passo a passo
6. Se pedirem c√°lculos SEM Œª e Œº, pe√ßa os par√¢metros
7. Sempre seja educativo, use emojis e explique o contexto pr√°tico

LEMBRE-SE: PORTUGU√äS BRASILEIRO SEMPRE!"""

            safe_temperature = max(0.0, min(2.0, self.temperature + 0.1))
            safe_max_tokens = max(100, min(4000, self.max_tokens // 2))

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_question}
                ],
                temperature=safe_temperature,
                max_tokens=safe_max_tokens
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"‚ùå DEBUG - Erro em general_help_response: {e}")
            return self._generate_fallback_help_response()

    def handle_error_with_context(self, user_question: str, error_context: str) -> str:
        """Usa Llama 3.1 8B para explicar erros de forma did√°tica"""
        try:
            system_prompt = """IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO!

Voc√™ √© o Milanesa, especialista em Teoria das Filas M/M/1.
Explique erros de forma did√°tica e ajude o usu√°rio a corrigir o problema.
LEMBRE-SE: SEMPRE EM PORTUGU√äS BRASILEIRO!"""

            user_prompt = f"""
            Pergunta do usu√°rio: {user_question}
            Erro encontrado: {error_context}

            Por favor, explique o erro de forma did√°tica e sugira como corrigir.
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=max(0.0, min(2.0, self.temperature)),
                max_tokens=max(100, min(4000, self.max_tokens // 2))
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"‚ùå DEBUG - Erro em handle_error_with_context: {e}")
            return f"‚ùå **Erro:** {error_context}\n\nüí° **Dica:** Certifique-se de fornecer os valores corretos de Œª e Œº."

    def _generate_fallback_response(self, calculation_result: Dict) -> str:
        """Resposta de fallback quando Groq n√£o est√° dispon√≠vel"""
        if "description" in calculation_result:
            return f"üçñ **Milanesa aqui!** Calculei para voc√™:\n\nüìä **Resultado:** {calculation_result['description']}"
        return "üçñ **Milanesa aqui!** C√°lculo realizado com sucesso!"

    def _generate_fallback_example_response(self, example_type: str, results: Dict) -> str:
        """Resposta de fallback para exemplos"""
        return f"üçñ **Milanesa resolveu o exemplo {example_type}!**\n\nResultados calculados com sucesso."

    def _generate_fallback_help_response(self) -> str:
        """Resposta de fallback para ajuda geral"""
        return """üçñ **Milanesa aqui!**

Sou especializada em Teoria das Filas M/M/1. Posso ajudar com:
- C√°lculos de utiliza√ß√£o (œÅ)
- N√∫mero m√©dio de clientes (L, Lq)
- Tempos m√©dios (W, Wq)
- Probabilidades (P0, Pn, P(N>k))
- Exemplos pr√°ticos (aeroporto, banco, etc.)

Como posso ajud√°-lo?"""


# Inst√¢ncia global do cliente Groq
try:
    groq_client = GroqClient()
    print("‚úÖ DEBUG - GroqClient inicializado com sucesso")
except Exception as e:
    print(f"‚ùå DEBUG - Erro ao inicializar GroqClient: {e}")
    groq_client = None